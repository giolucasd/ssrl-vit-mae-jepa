model:
  general:
    mask_ratio: 0.75
    image_size: 96
    patch_size: 6
    in_chans: 3

  encoder:
    embed_dim: 384
    depth: 12
    num_heads: 6

  decoder:
    decoder_embed_dim: 512
    decoder_depth: 4
    decoder_num_heads: 6

  head:
    emb_dim: 384
    dropout: 0.2

pretrain:
  seed: 73
  total_epochs: 200
  warmup_epochs: 20
  batch_size: 512
  base_learning_rate: 1.5e-4
  weight_decay: 0.05
  data_fraction: 1.00

train:
  seed: 73
  samples_per_class: 400
  total_epochs: 100
  warmup_epochs: 5
  batch_size: 256
  learning_rate: 3e-4
  weight_decay: 0.05
  freeze_encoder: true

logging:
  output_dir: outputs/pretrain/mae_100
  model_path: vit-mae.pt
  num_workers: 4

model:
  general:
    image_size: 96
    patch_size: 8
    in_chans: 3

  encoder:
    embed_dim: 144
    depth: 4
    num_heads: 6

  decoder:
    decoder_embed_dim: 192
    decoder_depth: 2
    decoder_num_heads: 6

  head:
    embed_dim: 144
    pool: cls

pretrain:
  mask_ratio_start: 0.75
  mask_ratio_end: 0.75
  mask_ramp_epochs: 5
  total_epochs: 800
  warmup_epochs: 20
  batch_size: 2000
  base_learning_rate: 1.5e-4
  weight_decay: 0.05
  data_fraction: 1.00
  val_split: 0.06
  num_workers: 4

train:
  samples_per_class: 400
  total_epochs: 100
  warmup_epochs: 10
  batch_size: 2000
  learning_rate: 3e-4
  weight_decay: 0.05
  freeze_encoder: true
  num_workers: 4
test:
  batch_size: 2000
  num_workers: 4

logging:
  output_dir_base: outputs
  model_path: vit-mae.pt

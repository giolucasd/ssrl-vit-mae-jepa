seed: 73

model:
  general:
    image_size: 96
    patch_size: 8
    in_chans: 3

  encoder:
    embed_dim: 384
    depth: 12
    num_heads: 6

  decoder:
    decoder_embed_dim: 256
    decoder_depth: 4
    decoder_num_heads: 8

  head:
    embed_dim: 384
    dropout: 0.0
    pool: cls

pretrain:
  mask_ratio_start: 0.5
  mask_ratio_end: 0.85
  mask_ramp_epochs: 150
  total_epochs: 800
  warmup_epochs: 20
  batch_size: 512
  base_learning_rate: 1.5e-4
  weight_decay: 0.05
  data_fraction: 1.00
  val_split: 0.05
  num_workers: 4
  output_dir_suffix: mae_t1

train:
  samples_per_class: 400
  total_epochs: 200
  warmup_epochs: 10
  batch_size: 1024
  learning_rate: 3e-4
  weight_decay: 0.05
  freeze_encoder: true
  num_workers: 4
  output_dir_suffix: mae_t1

test:
  batch_size: 512
  num_workers: 4
  output_dir_suffix: mae_t1

logging:
  output_dir_base: outputs
  model_path: vit-mae.pt

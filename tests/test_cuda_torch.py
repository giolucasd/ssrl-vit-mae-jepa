import time

import torch

print("==== Teste PyTorch + CUDA ====")

# Verifica disponibilidade
print(f"PyTorch vers√£o: {torch.__version__}")
print(f"CUDA dispon√≠vel: {torch.cuda.is_available()}")
if not torch.cuda.is_available():
    print("‚ö†Ô∏è  CUDA n√£o est√° dispon√≠vel. Verifique drivers e instala√ß√£o do PyTorch.")
    exit(1)

# Mostra informa√ß√µes da GPU
device_name = torch.cuda.get_device_name(0)
print(f"GPU detectada: {device_name}")
print(f"Vers√£o CUDA usada pelo PyTorch: {torch.version.cuda}")
print(f"Vers√£o cuDNN: {torch.backends.cudnn.version()}")

# Teste de aloca√ß√£o e opera√ß√£o
device = torch.device("cuda")
a = torch.randn((5000, 5000), device=device)
b = torch.randn((5000, 5000), device=device)

torch.cuda.synchronize()
start = time.time()
c = torch.matmul(a, b)  # opera√ß√£o pesada na GPU
torch.cuda.synchronize()
elapsed = time.time() - start

print(f"‚úÖ Multiplica√ß√£o de matrizes conclu√≠da com sucesso em {elapsed:.3f} s")
print(f"Resultado: m√©dia={c.mean().item():.5f}, desvio padr√£o={c.std().item():.5f}")

# Teste de transfer√™ncia CPU ‚Üî GPU
a_cpu = a.cpu()
a_gpu = a_cpu.to(device)
print("‚úÖ Transfer√™ncia CPU <-> GPU ok")

print("Tudo parece estar funcionando corretamente! üöÄ")
